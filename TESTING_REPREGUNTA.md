# ğŸ§ª GuÃ­a de Testing - Funcionalidad de Repregunta

Esta guÃ­a te ayudarÃ¡ a testear la nueva funcionalidad de repregunta implementada en el sistema.

## ğŸ“‹ Pre-requisitos

Antes de testear, asegÃºrate de tener:

1. **Servicios externos corriendo**:
   - Base de datos PostgreSQL
   - Servicio de embeddings (puerto 8001)
   - Microservicio vectorial (gRPC puerto 50052)
   - Microservicio relacional (gRPC puerto 50051)

2. **Variables de entorno configuradas** (`.env`):
   - `GEMINI_API_KEY` - Tu API key de Google Gemini
   - `AI_PROVIDER=gemini` (o el proveedor que uses)
   - ConfiguraciÃ³n de base de datos

3. **Dependencias instaladas**:
   ```bash
   cd backend
   pipenv install  # o pip install -r requirements.txt
   ```

## ğŸš€ OpciÃ³n 1: Testing Manual con el Servidor Completo

### Paso 1: Iniciar el Backend

```bash
cd backend
python3 main.py
```

El servidor deberÃ­a iniciar en `http://localhost:8000`

### Paso 2: Verificar que el servidor estÃ¡ corriendo

```bash
curl http://localhost:8000/api/health
```

DeberÃ­as ver:
```json
{
  "status": "healthy",
  "service": "simpla-backend",
  "version": "1.0.0"
}
```

### Paso 3: Autenticarse (obtener token)

Primero necesitas crear un usuario o usar uno existente:

```bash
# Registrar nuevo usuario
curl -X POST http://localhost:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "TestPassword123!",
    "full_name": "Test User"
  }'
```

Luego hacer login:

```bash
# Login
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "TestPassword123!"
  }'
```

Guarda el `access_token` de la respuesta.

### Paso 4: Testear la Repregunta

**Caso 1: Pregunta Vaga (deberÃ­a generar repregunta)**

```bash
TOKEN="tu_access_token_aqui"

curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "hÃ¡blame de contratos",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**: DeberÃ­a retornar una repregunta tipo:
> "Â¿Te refieres a contratos laborales, civiles, comerciales, de locaciÃ³n o algÃºn otro tipo especÃ­fico de contrato?"

**Observa los logs** para ver:
- âœ… "Analyzing question completeness..."
- âœ… "Question needs clarification: ..."
- âŒ NO deberÃ­a aparecer "Fetching legal context" (no llama a vector DB)

---

**Caso 2: Pregunta sin Contexto (deberÃ­a generar repregunta)**

```bash
curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "Â¿quÃ© dice el artÃ­culo 5?",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**:
> "Â¿De quÃ© ley o norma necesitas informaciÃ³n sobre el artÃ­culo 5?"

---

**Caso 3: Pregunta EspecÃ­fica (NO deberÃ­a generar repregunta)**

```bash
curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "Â¿cuÃ¡les son las causales de despido con justa causa segÃºn la LCT?",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**:
- Respuesta directa con informaciÃ³n legal
- En los logs deberÃ­a aparecer "Fetching legal context" (SÃ llama a vector DB)

---

**Caso 4: Respuesta a Repregunta (contextualizaciÃ³n)**

Primero haz una pregunta vaga, guarda el `session_id` de la respuesta, luego:

```bash
SESSION_ID="session_id_de_la_respuesta_anterior"

curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "laborales",
    "session_id": "'$SESSION_ID'",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**:
- Respuesta sobre contratos laborales
- En logs: "Skipping analysis - this is a response to a clarification question"
- En logs: "Contextualized question: hÃ¡blame de contratos laborales"

---

## ğŸ§ª OpciÃ³n 2: Testing con Script Python

Crea un archivo `test_repregunta.py`:

```python
#!/usr/bin/env python3
"""Script para testear la funcionalidad de repregunta."""

import asyncio
import sys
sys.path.insert(0, '/Users/inakibengolea/tesis/simpla-main/backend')

from features.conversations.question_analysis import analyze_question_completeness

async def test_question(question: str):
    """Test a single question."""
    print(f"\n{'='*60}")
    print(f"Testing: {question}")
    print('='*60)

    result = await analyze_question_completeness(question)

    print(f"âœ… Sufficient: {result.is_sufficient}")
    if not result.is_sufficient:
        print(f"â“ Clarification needed: {result.clarification_needed}")
    print(f"ğŸ“ Analysis: {result.analysis}")

async def main():
    """Run all tests."""
    test_cases = [
        "hÃ¡blame de contratos",
        "Â¿quÃ© dice el artÃ­culo 5?",
        "necesito informaciÃ³n sobre licencias",
        "Â¿cuÃ¡les son las causales de despido con justa causa segÃºn la LCT?",
        "Â¿quÃ© dice el CÃ³digo Civil sobre prescripciÃ³n de acciones?",
        "requisitos para registro",
    ]

    for question in test_cases:
        await test_question(question)
        await asyncio.sleep(1)  # Para no saturar la API

if __name__ == "__main__":
    asyncio.run(main())
```

Ejecutar:

```bash
cd /Users/inakibengolea/tesis/simpla-main/backend
python3 test_repregunta.py
```

---

## ğŸ§ª OpciÃ³n 3: Testing Unitario (sin servidor)

Crea un archivo `test_analysis_only.py`:

```python
#!/usr/bin/env python3
"""Test solo el anÃ¡lisis de completitud sin todo el pipeline."""

import asyncio
import sys
import os

# Configurar path
sys.path.insert(0, '/Users/inakibengolea/tesis/simpla-main/backend')

# Asegurarse de que las variables de entorno estÃ©n configuradas
os.environ.setdefault('GEMINI_API_KEY', 'tu_api_key_aqui')
os.environ.setdefault('AI_PROVIDER', 'gemini')

from features.conversations.question_analysis import (
    analyze_question_completeness,
    should_skip_analysis,
    get_contextualized_question
)

async def test_completeness_analysis():
    """Test anÃ¡lisis de completitud."""
    print("\nğŸ§ª Test 1: Pregunta vaga")
    result = await analyze_question_completeness("hÃ¡blame de contratos")
    assert not result.is_sufficient, "DeberÃ­a detectar que necesita clarificaciÃ³n"
    assert result.clarification_needed is not None
    print(f"âœ… DetectÃ³ necesidad de clarificaciÃ³n: {result.clarification_needed[:50]}...")

    print("\nğŸ§ª Test 2: Pregunta especÃ­fica")
    result = await analyze_question_completeness(
        "Â¿cuÃ¡les son las causales de despido con justa causa segÃºn la LCT?"
    )
    assert result.is_sufficient, "DeberÃ­a detectar que es suficiente"
    assert result.clarification_needed is None
    print("âœ… DetectÃ³ que es suficiente")

def test_skip_analysis():
    """Test lÃ³gica de skip."""
    print("\nğŸ§ª Test 3: Skip analysis cuando hay clarificaciÃ³n previa")

    # Caso 1: Sin metadata previa
    should_skip = should_skip_analysis("test", None)
    assert not should_skip
    print("âœ… No skip cuando no hay metadata")

    # Caso 2: Con needs_clarification = True
    should_skip = should_skip_analysis("test", {"needs_clarification": True})
    assert should_skip
    print("âœ… Skip cuando mensaje anterior necesitaba clarificaciÃ³n")

    # Caso 3: Con clarification_count >= 1
    should_skip = should_skip_analysis("test", {"clarification_count": 1})
    assert should_skip
    print("âœ… Skip cuando se alcanzÃ³ el lÃ­mite de repreguntas")

def test_contextualization():
    """Test contextualizaciÃ³n."""
    print("\nğŸ§ª Test 4: ContextualizaciÃ³n de preguntas")

    class MockMessage:
        def __init__(self, role, content):
            self.role = role
            self.content = content

    previous_messages = [
        MockMessage("user", "hÃ¡blame de contratos"),
        MockMessage("assistant", "Â¿quÃ© tipo de contratos?"),
    ]

    contextualized = get_contextualized_question(
        "laborales",
        previous_messages
    )

    assert "hÃ¡blame de contratos" in contextualized
    assert "laborales" in contextualized
    print(f"âœ… Pregunta contextualizada: {contextualized}")

async def main():
    """Run all tests."""
    print("="*60)
    print("ğŸ§ª Testing Repregunta Functionality")
    print("="*60)

    await test_completeness_analysis()
    test_skip_analysis()
    test_contextualization()

    print("\n" + "="*60)
    print("âœ… Todos los tests pasaron!")
    print("="*60)

if __name__ == "__main__":
    asyncio.run(main())
```

Ejecutar:

```bash
cd /Users/inakibengolea/tesis/simpla-main/backend
python3 test_analysis_only.py
```

---

## ğŸ“Š VerificaciÃ³n de Logs

Durante el testing, busca estos mensajes en los logs:

### âœ… Cuando detecta necesidad de clarificaciÃ³n:
```
INFO - Analyzing question completeness...
INFO - Question needs clarification: La pregunta es muy vaga...
INFO - Skipping vector DB - returning clarification
```

### âœ… Cuando es respuesta a repregunta:
```
INFO - Skipping analysis - this is a response to a clarification question
INFO - Contextualized question: hÃ¡blame de contratos laborales
INFO - Fetching legal context...
```

### âœ… Cuando pregunta es suficiente:
```
INFO - Analyzing question completeness...
INFO - Question analysis complete - Sufficient: True
INFO - Fetching legal context...
```

---

## ğŸ› Troubleshooting

### Error: "GEMINI_API_KEY not found"
- Verifica que tienes el `.env` configurado en `/backend/.env`
- Verifica que el archivo contiene `GEMINI_API_KEY=tu_clave_aqui`

### Error: "Connection refused to localhost:50052"
- El microservicio vectorial no estÃ¡ corriendo
- Inicia el servicio vectorial antes de testear

### Error: "Invalid JSON response from LLM"
- El LLM puede devolver texto adicional fuera del JSON
- Revisa los logs para ver la respuesta raw
- El cÃ³digo deberÃ­a manejar esto automÃ¡ticamente (limpieza de markdown)

### No se activa la repregunta
- Verifica los logs para ver el anÃ¡lisis del LLM
- Puede que el prompt necesite ajustes para tu modelo especÃ­fico
- Intenta con preguntas mÃ¡s vagas ("contratos", "artÃ­culo 5")

---

## ğŸ“ Casos de Prueba Recomendados

| Pregunta | Esperado | Verificar |
|----------|----------|-----------|
| "hÃ¡blame de contratos" | Repregunta | âŒ No llama vector DB |
| "Â¿quÃ© dice el artÃ­culo 5?" | Repregunta | âŒ No llama vector DB |
| "requisitos para registro" | Repregunta | âŒ No llama vector DB |
| "LCT artÃ­culo 245" | Respuesta directa | âœ… Llama vector DB |
| "despido sin justa causa LCT" | Respuesta directa | âœ… Llama vector DB |
| Respuesta: "laborales" (despuÃ©s de repregunta) | Respuesta directa | âœ… Usa contexto |

---

## ğŸ¯ PrÃ³ximos Pasos

DespuÃ©s de verificar que funciona:

1. **Ajustar el prompt** si es necesario (en `clarification_prompts.py`)
2. **Modificar lÃ­mite de repreguntas** si quieres mÃ¡s de 1 (en `should_skip_analysis`)
3. **Agregar mÃ©tricas** para medir ahorro de cÃ³mputo
4. **Testear con usuarios reales** para ver calidad de repreguntas

---

## ğŸ’¡ Tips

- Usa `tail -f` en los logs para ver el flujo en tiempo real
- Prueba con diferentes `chat_type` (normativa_nacional, constituciones, norma_chat)
- Prueba con diferentes `tone` (formal, academico, conciso)
- Mide el tiempo de respuesta - las repreguntas deberÃ­an ser mÃ¡s rÃ¡pidas (no hay vector DB)
