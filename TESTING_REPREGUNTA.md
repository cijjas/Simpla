# üß™ Gu√≠a de Testing - Funcionalidad de Repregunta

Esta gu√≠a te ayudar√° a testear la nueva funcionalidad de repregunta implementada en el sistema.

## üìã Pre-requisitos

Antes de testear, aseg√∫rate de tener:

1. **Servicios externos corriendo**:
   - Base de datos PostgreSQL
   - Servicio de embeddings (puerto 8001)
   - Microservicio vectorial (gRPC puerto 50052)
   - Microservicio relacional (gRPC puerto 50051)

2. **Variables de entorno configuradas** (`.env`):
   - `GEMINI_API_KEY` - Tu API key de Google Gemini
   - `AI_PROVIDER=gemini` (o el proveedor que uses)
   - Configuraci√≥n de base de datos

3. **Dependencias instaladas**:
   ```bash
   cd backend
   pipenv install  # o pip install -r requirements.txt
   ```

## üöÄ Opci√≥n 1: Testing Manual con el Servidor Completo

### Paso 1: Iniciar el Backend

```bash
cd backend
python3 main.py
```

El servidor deber√≠a iniciar en `http://localhost:8000`

### Paso 2: Verificar que el servidor est√° corriendo

```bash
curl http://localhost:8000/api/health
```

Deber√≠as ver:
```json
{
  "status": "healthy",
  "service": "simpla-backend",
  "version": "1.0.0"
}
```

### Paso 3: Autenticarse (obtener token)

Primero necesitas crear un usuario o usar uno existente:

```bash
# Registrar nuevo usuario
curl -X POST http://localhost:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "TestPassword123!",
    "full_name": "Test User"
  }'
```

Luego hacer login:

```bash
# Login
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "TestPassword123!"
  }'
```

Guarda el `access_token` de la respuesta.

### Paso 4: Testear la Repregunta

**Caso 1: Pregunta Vaga (deber√≠a generar repregunta)**

```bash
TOKEN="tu_access_token_aqui"

curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "h√°blame de contratos",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**: Deber√≠a retornar una repregunta tipo:
> "¬øTe refieres a contratos laborales, civiles, comerciales, de locaci√≥n o alg√∫n otro tipo espec√≠fico de contrato?"

**Observa los logs** para ver:
- ‚úÖ "Analyzing question completeness..."
- ‚úÖ "Question needs clarification: ..."
- ‚ùå NO deber√≠a aparecer "Fetching legal context" (no llama a vector DB)

---

**Caso 2: Pregunta sin Contexto (deber√≠a generar repregunta)**

```bash
curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "¬øqu√© dice el art√≠culo 5?",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**:
> "¬øDe qu√© ley o norma necesitas informaci√≥n sobre el art√≠culo 5?"

---

**Caso 3: Pregunta Espec√≠fica (NO deber√≠a generar repregunta)**

```bash
curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "¬øcu√°les son las causales de despido con justa causa seg√∫n la LCT?",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**:
- Respuesta directa con informaci√≥n legal
- En los logs deber√≠a aparecer "Fetching legal context" (S√ç llama a vector DB)

---

**Caso 4: Respuesta a Repregunta (contextualizaci√≥n)**

Primero haz una pregunta vaga, guarda el `session_id` de la respuesta, luego:

```bash
SESSION_ID="session_id_de_la_respuesta_anterior"

curl -X POST http://localhost:8000/api/conversations/message \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "content": "laborales",
    "session_id": "'$SESSION_ID'",
    "chat_type": "normativa_nacional",
    "tone": "default"
  }'
```

**Resultado esperado**:
- Respuesta sobre contratos laborales
- En logs: "Skipping analysis - this is a response to a clarification question"
- En logs: "Contextualized question: h√°blame de contratos laborales"

---

## üß™ Opci√≥n 2: Testing con Script Python

Crea un archivo `test_repregunta.py`:

```python
#!/usr/bin/env python3
"""Script para testear la funcionalidad de repregunta."""

import asyncio
import sys
sys.path.insert(0, '/Users/inakibengolea/tesis/simpla-main/backend')

from features.conversations.question_analysis import analyze_question_completeness

async def test_question(question: str):
    """Test a single question."""
    print(f"\n{'='*60}")
    print(f"Testing: {question}")
    print('='*60)

    result = await analyze_question_completeness(question)

    print(f"‚úÖ Sufficient: {result.is_sufficient}")
    if not result.is_sufficient:
        print(f"‚ùì Clarification needed: {result.clarification_needed}")
    print(f"üìù Analysis: {result.analysis}")

async def main():
    """Run all tests."""
    test_cases = [
        "h√°blame de contratos",
        "¬øqu√© dice el art√≠culo 5?",
        "necesito informaci√≥n sobre licencias",
        "¬øcu√°les son las causales de despido con justa causa seg√∫n la LCT?",
        "¬øqu√© dice el C√≥digo Civil sobre prescripci√≥n de acciones?",
        "requisitos para registro",
    ]

    for question in test_cases:
        await test_question(question)
        await asyncio.sleep(1)  # Para no saturar la API

if __name__ == "__main__":
    asyncio.run(main())
```

Ejecutar:

```bash
cd /Users/inakibengolea/tesis/simpla-main/backend
python3 test_repregunta.py
```

---

## üß™ Opci√≥n 3: Testing Unitario (sin servidor)

Crea un archivo `test_analysis_only.py`:

```python
#!/usr/bin/env python3
"""Test solo el an√°lisis de completitud sin todo el pipeline."""

import asyncio
import sys
import os

# Configurar path
sys.path.insert(0, '/Users/inakibengolea/tesis/simpla-main/backend')

# Asegurarse de que las variables de entorno est√©n configuradas
os.environ.setdefault('GEMINI_API_KEY', 'tu_api_key_aqui')
os.environ.setdefault('AI_PROVIDER', 'gemini')

from features.conversations.question_analysis import (
    analyze_question_completeness,
    should_skip_analysis,
    get_contextualized_question
)

async def test_completeness_analysis():
    """Test an√°lisis de completitud."""
    print("\nüß™ Test 1: Pregunta vaga")
    result = await analyze_question_completeness("h√°blame de contratos")
    assert not result.is_sufficient, "Deber√≠a detectar que necesita clarificaci√≥n"
    assert result.clarification_needed is not None
    print(f"‚úÖ Detect√≥ necesidad de clarificaci√≥n: {result.clarification_needed[:50]}...")

    print("\nüß™ Test 2: Pregunta espec√≠fica")
    result = await analyze_question_completeness(
        "¬øcu√°les son las causales de despido con justa causa seg√∫n la LCT?"
    )
    assert result.is_sufficient, "Deber√≠a detectar que es suficiente"
    assert result.clarification_needed is None
    print("‚úÖ Detect√≥ que es suficiente")

def test_skip_analysis():
    """Test l√≥gica de skip."""
    print("\nüß™ Test 3: Skip analysis cuando hay clarificaci√≥n previa")

    # Caso 1: Sin metadata previa
    should_skip = should_skip_analysis("test", None)
    assert not should_skip
    print("‚úÖ No skip cuando no hay metadata")

    # Caso 2: Con needs_clarification = True
    should_skip = should_skip_analysis("test", {"needs_clarification": True})
    assert should_skip
    print("‚úÖ Skip cuando mensaje anterior necesitaba clarificaci√≥n")

    # Caso 3: Con clarification_count >= 1
    should_skip = should_skip_analysis("test", {"clarification_count": 1})
    assert should_skip
    print("‚úÖ Skip cuando se alcanz√≥ el l√≠mite de repreguntas")

def test_contextualization():
    """Test contextualizaci√≥n."""
    print("\nüß™ Test 4: Contextualizaci√≥n de preguntas")

    class MockMessage:
        def __init__(self, role, content):
            self.role = role
            self.content = content

    previous_messages = [
        MockMessage("user", "h√°blame de contratos"),
        MockMessage("assistant", "¬øqu√© tipo de contratos?"),
    ]

    contextualized = get_contextualized_question(
        "laborales",
        previous_messages
    )

    assert "h√°blame de contratos" in contextualized
    assert "laborales" in contextualized
    print(f"‚úÖ Pregunta contextualizada: {contextualized}")

async def main():
    """Run all tests."""
    print("="*60)
    print("üß™ Testing Repregunta Functionality")
    print("="*60)

    await test_completeness_analysis()
    test_skip_analysis()
    test_contextualization()

    print("\n" + "="*60)
    print("‚úÖ Todos los tests pasaron!")
    print("="*60)

if __name__ == "__main__":
    asyncio.run(main())
```

Ejecutar:

```bash
cd /Users/inakibengolea/tesis/simpla-main/backend
python3 test_analysis_only.py
```

---

## üìä Verificaci√≥n de Logs

Durante el testing, busca estos mensajes en los logs:

### ‚úÖ Cuando detecta necesidad de clarificaci√≥n:
```
INFO - Analyzing question completeness...
INFO - Question needs clarification: La pregunta es muy vaga...
INFO - Skipping vector DB - returning clarification
```

### ‚úÖ Cuando es respuesta a repregunta:
```
INFO - Skipping analysis - this is a response to a clarification question
INFO - Contextualized question: h√°blame de contratos laborales
INFO - Fetching legal context...
```

### ‚úÖ Cuando pregunta es suficiente:
```
INFO - Analyzing question completeness...
INFO - Question analysis complete - Sufficient: True
INFO - Fetching legal context...
```

---

## üêõ Troubleshooting

### Error: "GEMINI_API_KEY not found"
- Verifica que tienes el `.env` configurado en `/backend/.env`
- Verifica que el archivo contiene `GEMINI_API_KEY=tu_clave_aqui`

### Error: "Connection refused to localhost:50052"
- El microservicio vectorial no est√° corriendo
- Inicia el servicio vectorial antes de testear

### Error: "Invalid JSON response from LLM"
- El LLM puede devolver texto adicional fuera del JSON
- Revisa los logs para ver la respuesta raw
- El c√≥digo deber√≠a manejar esto autom√°ticamente (limpieza de markdown)

### No se activa la repregunta
- Verifica los logs para ver el an√°lisis del LLM
- Puede que el prompt necesite ajustes para tu modelo espec√≠fico
- Intenta con preguntas m√°s vagas ("contratos", "art√≠culo 5")

---

## üìù Casos de Prueba Recomendados

| Pregunta | Esperado | Verificar |
|----------|----------|-----------|
| "h√°blame de contratos" | Repregunta | ‚ùå No llama vector DB |
| "¬øqu√© dice el art√≠culo 5?" | Repregunta | ‚ùå No llama vector DB |
| "requisitos para registro" | Repregunta | ‚ùå No llama vector DB |
| "LCT art√≠culo 245" | Respuesta directa | ‚úÖ Llama vector DB |
| "despido sin justa causa LCT" | Respuesta directa | ‚úÖ Llama vector DB |
| Respuesta: "laborales" (despu√©s de repregunta) | Respuesta directa | ‚úÖ Usa contexto |

---

## üéØ Pr√≥ximos Pasos

Despu√©s de verificar que funciona:

1. **Ajustar el prompt** si es necesario (en `clarification_prompts.py`)
2. **Modificar l√≠mite de repreguntas** si quieres m√°s de 1 (en `should_skip_analysis`)
3. **Agregar m√©tricas** para medir ahorro de c√≥mputo
4. **Testear con usuarios reales** para ver calidad de repreguntas

---

## üí° Tips

- Usa `tail -f` en los logs para ver el flujo en tiempo real
- Prueba con diferentes `chat_type` (normativa_nacional, constituciones, norma_chat)
- Prueba con diferentes `tone` (formal, academico, conciso)
- Mide el tiempo de respuesta - las repreguntas deber√≠an ser m√°s r√°pidas (no hay vector DB)
